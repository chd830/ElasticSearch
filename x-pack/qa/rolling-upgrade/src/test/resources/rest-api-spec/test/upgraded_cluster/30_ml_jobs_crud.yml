setup:
 - do:
     cluster.health:
        wait_for_status: green
        wait_for_nodes: 3
        # wait for long enough that we give delayed unassigned shards to stop being delayed
        timeout: 70s

---
"Test check old jobs":

  - do:
      xpack.ml.get_job_stats:
        job_id: old-cluster-job
  - match: { jobs.0.data_counts.processed_record_count: 2 }
  - is_true: jobs.0.model_size_stats

  - do:
      xpack.ml.get_job_stats:
        job_id: mixed-cluster-job
  - match: { jobs.0.data_counts.processed_record_count: 2 }
  - is_true: jobs.0.model_size_stats

  - do:
      xpack.ml.get_buckets:
        job_id: old-cluster-job
  - match: { count: 1 }

  - do:
      xpack.ml.get_buckets:
        job_id: mixed-cluster-job
  - match: { count: 1 }

---
"Test job with pre 6.4 rules":

  - do:
      xpack.ml.get_jobs:
        job_id: job-with-old-rules
  - match: { count: 1 }
  - is_false: jobs.0.analysis_config.detectors.0.rules
  - is_false: jobs.0.analysis_config.detectors.0.custom_rules

---
"Test get job with function shortcut should expand":

  - do:
      xpack.ml.get_jobs:
        job_id: old-cluster-function-shortcut-expansion
  - match: { count: 1 }
  - match: { jobs.0.analysis_config.detectors.0.function: "non_zero_count" }

---
"Test model memory limit is updated":
# Jobs created in 6.1.x and 6.2.x underestimated the necessary model memory
# limit, check the limit has been updated.
# Opening the job updates the limit
  - do:
      xpack.ml.open_job:
        job_id: old-cluster-job-with-model-mem-limit

  - do:
      xpack.ml.get_jobs:
        job_id: old-cluster-job-with-model-mem-limit
  - match: { count: 1 }
  - match: { jobs.0.analysis_limits.model_memory_limit: 130mb }
